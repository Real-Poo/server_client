# GPU κΈ°λ° μ›κ²© λ°μ¤ν¬ν†± μ¤νΈλ¦¬λ° ν΄λΌμ΄μ–ΈνΈ

μ„λ²„μ—μ„ κ°€μƒ λ°μ¤ν¬ν†±μ„ μΊ΅μ²ν•κ³  GPUλ΅ μΈμ½”λ”©ν• ν™”λ©΄ λ°μ΄ν„°λ¥Ό μ›Ήμ†μΌ“μ„ ν†µν•΄ μμ‹ ν• ν›„, ν΄λΌμ΄μ–ΈνΈμ—μ„ GPUλ¥Ό ν™μ©ν•μ—¬ μ‹¤μ‹κ°„μΌλ΅ λ””μ½”λ”©ν•λ” μ›κ²© λ°μ¤ν¬ν†± μ¤νΈλ¦¬λ° μ‹μ¤ν…μ…λ‹λ‹¤.

## π“‹ λ©μ°¨

- [κ°μ”](#κ°μ”)
- [μ‹μ¤ν… μ”κµ¬μ‚¬ν•­](#μ‹μ¤ν…-μ”κµ¬μ‚¬ν•­)
- [μ‚¬μ© λ°©λ²•](#μ‚¬μ©-λ°©λ²•)
- [μ½”λ“ κµ¬μ΅°](#μ½”λ“-κµ¬μ΅°)
- [μ„±λ¥ μµμ ν™”](#μ„±λ¥-μµμ ν™”)
- [νΈλ¬λΈ”μν…](#νΈλ¬λΈ”μν…)

## π― κ°μ”

μ΄ ν”„λ΅μ νΈλ” λ‹¤μ λ‘ κ°€μ§€ ν΄λΌμ΄μ–ΈνΈ κµ¬ν„μ„ μ κ³µν•©λ‹λ‹¤:

1. **Python ν΄λΌμ΄μ–ΈνΈ** (`test_client.py`): PyTorchλ¥Ό μ‚¬μ©ν•μ—¬ GPUμ—μ„ λ””μ½”λ”©ν•κ³  μ„±λ¥ ν†µκ³„λ¥Ό μ½μ†”μ— μ¶λ ¥
2. **μ›Ή ν΄λΌμ΄μ–ΈνΈ** (`client.html`): ONNX Runtimeμ„ μ‚¬μ©ν•μ—¬ λΈλΌμ°μ €μ—μ„ λ””μ½”λ”©ν•κ³  ν™”λ©΄μ— ν‘μ‹

μ„λ²„λ” ν™”λ©΄μ„ μΊ΅μ²ν•κ³  CNN μΈμ½”λ”λ΅ μ••μ¶•ν• ν›„, zlibμΌλ΅ μ••μ¶•ν•μ—¬ μ›Ήμ†μΌ“μ„ ν†µν•΄ μ „μ†΅ν•©λ‹λ‹¤. ν΄λΌμ΄μ–ΈνΈλ” μμ‹ ν• λ°μ΄ν„°λ¥Ό μ••μ¶• ν•΄μ ν•κ³  GPUλ΅ λ””μ½”λ”©ν•μ—¬ μ›λ³Έ ν™”λ©΄μ„ λ³µμ›ν•©λ‹λ‹¤.

## π’» μ‹μ¤ν… μ”κµ¬μ‚¬ν•­

### κ³µν†µ μ”κµ¬μ‚¬ν•­

- **Docker**: Docker Engine 20.10 μ΄μƒ
- **NVIDIA Container Toolkit**: GPU μ‚¬μ©μ„ μ„ν• Docker ν”λ¬κ·ΈμΈ
- **GPU**: CUDA μ§€μ› NVIDIA GPU (μ„λ²„ λ° Python ν΄λΌμ΄μ–ΈνΈμ— ν•„μ”)
- **μ΄μμ²΄μ **: Linux (κ¶μ¥), Dockerκ°€ μ§€μ›λλ” λ‹¤λ¥Έ μ΄μμ²΄μ 

### μ„λ²„

- **Docker μ΄λ―Έμ§€**: `Dockerfile.server` κΈ°λ°
- **ν¬νΈ**: 8765 (μ›Ήμ†μΌ“)

### Python ν΄λΌμ΄μ–ΈνΈ

- **Docker μ΄λ―Έμ§€**: `Dockerfile.test` κΈ°λ°
- **λ„¤νΈμ›ν¬**: νΈμ¤νΈ λ„¤νΈμ›ν¬ λ¨λ“ μ‚¬μ©

### μ›Ή ν΄λΌμ΄μ–ΈνΈ

- **λΈλΌμ°μ €**: Chrome, Edge, Firefox (μµμ‹  λ²„μ „)
- **GPU**: WebGL λλ” WebNN μ§€μ› GPU
- **μ„λ²„**: HTTP μ„λ²„ (μ •μ  νμΌ νΈμ¤ν…)

## π€ μ‚¬μ© λ°©λ²•

### μ„λ²„ μ‹¤ν–‰

1. **μ„λ²„ Docker μ΄λ―Έμ§€ λΉλ“**

```bash
docker build -f Dockerfile.server -t remote-desktop-encoder .
```

2. **μ„λ²„ μ»¨ν…μ΄λ„ μ‹¤ν–‰**

```bash
docker run --gpus all -p 8765:8765 --rm \
  -v /tmp/.X11-unix:/tmp/.X11-unix \
  -e DISPLAY=:1 \
  -e QT_X11_NO_MITSHM=1 \
  -e _X11_NO_MITSHM=1 \
  -e _MITSHM=0 \
  remote-desktop-encoder
```

λλ” μ‹¤ν–‰ μ¤ν¬λ¦½νΈ μ‚¬μ©:

```bash
./run_headless.sh
```

μ„λ²„λ” κ°€μƒ λ””μ¤ν”λ μ΄(Xvfb)μ—μ„ ν™”λ©΄μ„ μΊ΅μ²ν•κ³  GPUλ΅ μΈμ½”λ”©ν• ν›„ μ›Ήμ†μΌ“ ν¬νΈ 8765λ΅ μ „μ†΅ν•©λ‹λ‹¤.

### Python ν΄λΌμ΄μ–ΈνΈ μ‹¤ν–‰ (Docker)

1. **ν΄λΌμ΄μ–ΈνΈ Docker μ΄λ―Έμ§€ λΉλ“**

```bash
docker build -f Dockerfile.test -t test-client .
```

2. **ν΄λΌμ΄μ–ΈνΈ μ»¨ν…μ΄λ„ μ‹¤ν–‰**

μ„λ²„κ°€ μ‹¤ν–‰ μ¤‘μΈ μƒνƒμ—μ„ λ‹¤μ λ…λ Ήμ–΄λ΅ ν΄λΌμ΄μ–ΈνΈλ¥Ό μ‹¤ν–‰ν•©λ‹λ‹¤:

```bash
docker run --gpus all --rm --network host test-client
```

λλ” μ‹¤ν–‰ μ¤ν¬λ¦½νΈ μ‚¬μ©:

```bash
./run_test.sh
```

**μ°Έκ³ :**
- `--gpus all`: GPU μ ‘κ·Ό κ¶ν• λ¶€μ—¬ (ν•„μ)
- `--network host`: νΈμ¤νΈ λ„¤νΈμ›ν¬ λ¨λ“λ΅ μ„λ²„μ™€ ν†µμ‹ 
- `--rm`: μ»¨ν…μ΄λ„ μΆ…λ£ μ‹ μλ™ μ‚­μ 

3. **μ„±λ¥ ν†µκ³„ ν™•μΈ**

ν΄λΌμ΄μ–ΈνΈλ” μ½μ†”μ— λ‹¤μκ³Ό κ°™μ€ μ„±λ¥ ν†µκ³„λ¥Ό μ‹¤μ‹κ°„μΌλ΅ μ¶λ ¥ν•©λ‹λ‹¤:

- **ν”„λ μ„ λ²νΈ**: μμ‹ ν• ν”„λ μ„ μ
- **FPS**: μ΄λ‹Ή ν”„λ μ„ μ
- **μ§€μ—°μ‹κ°„**: μ„λ²„μ—μ„ ν΄λΌμ΄μ–ΈνΈκΉμ§€μ λ„¤νΈμ›ν¬ μ§€μ—° (ms)
- **λ°μ΄ν„° ν¬κΈ°**: μμ‹ ν• μ••μ¶• λ°μ΄ν„° ν¬κΈ° (bytes)
- **λ””μ½”λ”© μ‹κ°„**: GPU λ””μ½”λ”©μ— μ†μ”λ μ‹κ°„ (ms)
- **ν‰κ·  λ””μ½”λ”© μ‹κ°„**: λ„μ  ν‰κ·  λ””μ½”λ”© μ‹κ°„ (ms)

μμ‹ μ¶λ ¥:
```
π”§ μ‚¬μ© μ¤‘μΈ λ””λ°”μ΄μ¤: cuda
π“¦ λ””μ½”λ” λ¨λΈ λ΅λ“ μ™„λ£
β… μ„λ²„μ— μ—°κ²°λ¨: ws://localhost:8765
π“ ν”„λ μ„ #1 | FPS: 30.0 | μ§€μ—°: 45.2ms | ν¬κΈ°: 12345 bytes | λ””μ½”λ”©: 8.5ms (ν‰κ· : 8.5ms)
π“ ν”„λ μ„ #2 | FPS: 30.1 | μ§€μ—°: 46.1ms | ν¬κΈ°: 12340 bytes | λ””μ½”λ”©: 8.3ms (ν‰κ· : 8.4ms)
...
π“ μ΄ 100κ° ν”„λ μ„ μμ‹  μ™„λ£ (ν‰κ·  FPS: 30.2, ν‰κ·  λ””μ½”λ”©: 8.4ms)
```

4. **μΆ…λ£**

`Ctrl+C`λ¥Ό λλ¬ ν΄λΌμ΄μ–ΈνΈ μ»¨ν…μ΄λ„λ¥Ό μΆ…λ£ν•©λ‹λ‹¤. `--rm` ν”λκ·Έλ΅ μΈν•΄ μ»¨ν…μ΄λ„λ” μλ™μΌλ΅ μ‚­μ λ©λ‹λ‹¤.

### μ›Ή ν΄λΌμ΄μ–ΈνΈ μ‹¤ν–‰

1. **ONNX λ¨λΈ μ¤€λΉ„**

`decoder.onnx` νμΌμ΄ `client.html`κ³Ό κ°™μ€ λ””λ ‰ν† λ¦¬μ— μλ”μ§€ ν™•μΈν•μ„Έμ”.

2. **HTTP μ„λ²„ μ‹μ‘**

```bash
python -m http.server 8000
```

3. **λΈλΌμ°μ €μ—μ„ μ ‘μ†**

```
http://localhost:8000/client.html
```

4. **ν™”λ©΄ ν™•μΈ**

- μΊ”λ²„μ¤μ— μ›κ²© λ°μ¤ν¬ν†± ν™”λ©΄μ΄ ν‘μ‹λ©λ‹λ‹¤
- FPSμ™€ μ§€μ—°μ‹κ°„μ΄ ν™”λ©΄ ν•λ‹¨μ— ν‘μ‹λ©λ‹λ‹¤

## π“ μ½”λ“ κµ¬μ΅°

### μ£Όμ” νμΌ

- **`test_client.py`**: Python ν΄λΌμ΄μ–ΈνΈ λ©”μΈ νμΌ (GPU λ””μ½”λ”© λ° μ„±λ¥ μΈ΅μ •)
- **`client.html`**: μ›Ή ν΄λΌμ΄μ–ΈνΈ HTML νμΌ
- **`decoder_model.py`**: λ””μ½”λ” λ¨λΈ μ •μ λ° ONNX λ³€ν™ μ¤ν¬λ¦½νΈ
- **`Dockerfile.server`**: μ„λ²„ Docker μ΄λ―Έμ§€ λΉλ“ νμΌ
- **`Dockerfile.test`**: ν΄λΌμ΄μ–ΈνΈ Docker μ΄λ―Έμ§€ λΉλ“ νμΌ
- **`run_headless.sh`**: μ„λ²„ μ‹¤ν–‰ μ¤ν¬λ¦½νΈ
- **`run_test.sh`**: ν΄λΌμ΄μ–ΈνΈ μ‹¤ν–‰ μ¤ν¬λ¦½νΈ

### λ°μ΄ν„° νλ¦„

**Python ν΄λΌμ΄μ–ΈνΈ:**
```
μ„λ²„ β†’ [μΈμ½”λ”©] β†’ [μ••μ¶•] β†’ [μ›Ήμ†μΌ“ μ „μ†΅] β†’ ν΄λΌμ΄μ–ΈνΈ β†’ [μμ‹ ] β†’ [μ••μ¶• ν•΄μ ] β†’ [GPU λ””μ½”λ”©] β†’ [μ„±λ¥ ν†µκ³„ μ¶λ ¥]
```

**μ›Ή ν΄λΌμ΄μ–ΈνΈ:**
```
μ„λ²„ β†’ [μΈμ½”λ”©] β†’ [μ••μ¶•] β†’ [μ›Ήμ†μΌ“ μ „μ†΅] β†’ ν΄λΌμ΄μ–ΈνΈ β†’ [μμ‹ ] β†’ [μ••μ¶• ν•΄μ ] β†’ [GPU λ””μ½”λ”©] β†’ [ν™”λ©΄ ν‘μ‹]
```

### λ©”μ‹μ§€ ν•μ‹

μ„λ²„μ—μ„ μ „μ†΅ν•λ” λ©”μ‹μ§€λ” λ‹¤μ ν•μ‹μ…λ‹λ‹¤:

```
[ν—¤λ” κΈΈμ΄ (4 bytes)] [ν—¤λ” (JSON)] [νμ΄λ΅λ“ (zlib μ••μ¶•λ latent λ°μ΄ν„°)]
```

**ν—¤λ” κµ¬μ΅°:**
```json
{
    "w": 80,           // latent λ„λΉ„
    "h": 45,           // latent λ†’μ΄
    "c": 64,           // μ±„λ„ μ
    "scale": 0.1,      // μ–‘μν™” μ¤μΌ€μΌ
    "orig_w": 1280,    // μ›λ³Έ λ„λΉ„
    "orig_h": 720,     // μ›λ³Έ λ†’μ΄
    "timestamp": 1234567890.123  // νƒ€μ„μ¤νƒ¬ν”„
}
```

### ν΄λΌμ΄μ–ΈνΈ λ™μ‘ κ³Όμ •

#### Python ν΄λΌμ΄μ–ΈνΈ (`test_client.py`)

```python
1. λ””μ½”λ” λ¨λΈ μ΄κΈ°ν™” (GPU/CPU)
2. μ›Ήμ†μΌ“ μ„λ²„μ— μ—°κ²°
3. λ°λ³µ:
   a. λ©”μ‹μ§€ μμ‹ 
   b. ν—¤λ” νμ‹± (κΈΈμ΄ + JSON)
   c. zlib μ••μ¶• ν•΄μ 
   d. int8 β†’ float32 λ³€ν™ (μ¤μΌ€μΌ μ μ©)
   e. GPUμ—μ„ λ””μ½”λ”© (μ‹κ°„ μΈ΅μ •)
   f. μ„±λ¥ ν†µκ³„ κ³„μ‚° (FPS, μ§€μ—°μ‹κ°„, λ””μ½”λ”© μ‹κ°„)
   g. μ½μ†”μ— ν†µκ³„ μ¶λ ¥
```

#### μ›Ή ν΄λΌμ΄μ–ΈνΈ (`client.html`)

```javascript
1. ONNX Runtime μ΄κΈ°ν™” (WebGL/WebNN)
2. ONNX λ¨λΈ λ΅λ“
3. μ›Ήμ†μΌ“ μ„λ²„μ— μ—°κ²°
4. λ°λ³µ:
   a. λ©”μ‹μ§€ μμ‹  (ArrayBuffer)
   b. ν—¤λ” νμ‹±
   c. pakoλ΅ μ••μ¶• ν•΄μ 
   d. int8 β†’ float32 λ³€ν™
   e. ONNX RuntimeμΌλ΅ λ””μ½”λ”©
   f. ν…μ„ β†’ ImageData λ³€ν™
   g. Canvasμ— λ λ”λ§
```

## β΅ μ„±λ¥ μµμ ν™”

### GPU μ‚¬μ© ν™•μΈ

**Python ν΄λΌμ΄μ–ΈνΈ:**

```python
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print(f"π”§ μ‚¬μ© μ¤‘μΈ λ””λ°”μ΄μ¤: {device}")
```

CUDAκ°€ μ‚¬μ© κ°€λ¥ν• κ²½μ° μλ™μΌλ΅ GPUλ¥Ό μ‚¬μ©ν•©λ‹λ‹¤. ν΄λΌμ΄μ–ΈνΈ μ‹¤ν–‰ μ‹ μ‚¬μ© μ¤‘μΈ λ””λ°”μ΄μ¤κ°€ μ½μ†”μ— μ¶λ ¥λ©λ‹λ‹¤.

**μ›Ή ν΄λΌμ΄μ–ΈνΈ:**

λΈλΌμ°μ € μ½μ†”μ—μ„ μ‹¤ν–‰ ν”„λ΅λ°”μ΄λ”λ¥Ό ν™•μΈν•  μ μμµλ‹λ‹¤:
- `webgl`: GPU κ°€μ† (WebGL)
- `webnn`: NPU κ°€μ† (μ§€μ›λλ” κ²½μ°)
- `cpu`: CPUλ§ μ‚¬μ©

### μ„±λ¥ ν–¥μƒ ν

1. **GPU λ©”λ¨λ¦¬ κ΄€λ¦¬**
   - λ°°μΉ ν¬κΈ°λ¥Ό μ΅°μ •ν•μ—¬ GPU λ©”λ¨λ¦¬ μ‚¬μ©λ‰ μµμ ν™”
   - λ¶ν•„μ”ν• ν…μ„λ” μ¦‰μ‹ ν•΄μ 

2. **λ„¤νΈμ›ν¬ μµμ ν™”**
   - μ›Ήμ†μΌ“ λ²„νΌ ν¬κΈ° μ΅°μ •: `max_size=1_000_000`
   - μ••μ¶• λ λ²¨ μ΅°μ • (μ„λ²„ μΈ΅)

3. **μ„±λ¥ λ¨λ‹ν„°λ§**
   - `test_client.py`λ” κ° ν”„λ μ„μ λ””μ½”λ”© μ‹κ°„μ„ μΈ΅μ •ν•μ—¬ μ¶λ ¥
   - 100ν”„λ μ„λ§λ‹¤ λ„μ  ν†µκ³„ μ¶λ ¥
   - μ›Ή: RequestAnimationFrame ν™μ© (ν•„μ”μ‹)

## π”§ νΈλ¬λΈ”μν…

### Docker κ΄€λ ¨

**λ¬Έμ : GPUλ¥Ό μ‚¬μ©ν•  μ μ—†μ**

```
docker: Error response from daemon: could not select device driver "" with capabilities: [[gpu]].
```

**ν•΄κ²° λ°©λ²•:**
- NVIDIA Container Toolkit μ„¤μΉ ν™•μΈ:
  ```bash
  # Ubuntu/Debian
  distribution=$(. /etc/os-release;echo $ID$VERSION_ID)
  curl -s -L https://nvidia.github.io/nvidia-docker/gpgkey | sudo apt-key add -
  curl -s -L https://nvidia.github.io/nvidia-docker/$distribution/nvidia-docker.list | sudo tee /etc/apt/sources.list.d/nvidia-docker.list
  sudo apt-get update && sudo apt-get install -y nvidia-container-toolkit
  sudo systemctl restart docker
  ```
- Dockerκ°€ GPUλ¥Ό μΈμ‹ν•λ”μ§€ ν™•μΈ:
  ```bash
  docker run --rm --gpus all nvidia/cuda:11.8.0-base-ubuntu20.04 nvidia-smi
  ```

**λ¬Έμ : μ„λ²„ μ»¨ν…μ΄λ„ μ‹¤ν–‰ μ‹¤ν¨**

```
Error: cannot connect to X server :1
```

**ν•΄κ²° λ°©λ²•:**
- Dockerfile.serverμ—μ„ Xvfbκ°€ μλ™μΌλ΅ μ‹μ‘λλ„λ΅ μ„¤μ •λμ–΄ μμµλ‹λ‹¤
- μ»¨ν…μ΄λ„ λ΅κ·Έ ν™•μΈ:
  ```bash
  docker logs <container_id>
  ```

**λ¬Έμ : ν΄λΌμ΄μ–ΈνΈκ°€ μ„λ²„μ— μ—°κ²°ν•  μ μ—†μ**

```
ConnectionRefusedError: [Errno 61] Connection refused
```

**ν•΄κ²° λ°©λ²•:**
- μ„λ²„ μ»¨ν…μ΄λ„κ°€ μ‹¤ν–‰ μ¤‘μΈμ§€ ν™•μΈ:
  ```bash
  docker ps
  ```
- μ„λ²„ μ»¨ν…μ΄λ„κ°€ ν¬νΈ 8765λ¥Ό λ¦¬μ¤λ‹ν•λ”μ§€ ν™•μΈ:
  ```bash
  docker port <container_id>
  ```
- ν΄λΌμ΄μ–ΈνΈκ°€ `--network host` μµμ…μΌλ΅ μ‹¤ν–‰λμ—λ”μ§€ ν™•μΈ
- μ„λ²„μ™€ ν΄λΌμ΄μ–ΈνΈκ°€ κ°™μ€ λ„¤νΈμ›ν¬μ— μλ”μ§€ ν™•μΈ

### Python ν΄λΌμ΄μ–ΈνΈ

**λ¬Έμ : CUDAλ¥Ό μ‚¬μ©ν•  μ μ—†μ**

```
π”§ μ‚¬μ© μ¤‘μΈ λ””λ°”μ΄μ¤: cpu
```

**ν•΄κ²° λ°©λ²•:**
- Docker μ»¨ν…μ΄λ„μ— `--gpus all` ν”λκ·Έκ°€ ν¬ν•¨λμ–΄ μλ”μ§€ ν™•μΈ
- NVIDIA Container Toolkitμ΄ μ„¤μΉλμ–΄ μλ”μ§€ ν™•μΈ
- νΈμ¤νΈ μ‹μ¤ν…μ—μ„ GPUκ°€ μΈμ‹λλ”μ§€ ν™•μΈ:
  ```bash
  nvidia-smi
  ```

**λ¬Έμ : λ””μ½”λ”© μ¤λ¥**

```
RuntimeError: Expected tensor to have size ...
```

**ν•΄κ²° λ°©λ²•:**
- μ„λ²„μ™€ ν΄λΌμ΄μ–ΈνΈμ λ¨λΈ λ²„μ „ μΌμΉ ν™•μΈ
- ν—¤λ”μ `w`, `h`, `c` κ°’μ΄ μ¬λ°”λ¥Έμ§€ ν™•μΈ
- λ””μ½”λ” μ±„λ„ μ(`c=64`)κ°€ μ„λ²„ μΈμ½”λ”μ™€ μΌμΉν•λ”μ§€ ν™•μΈ

### μ›Ή ν΄λΌμ΄μ–ΈνΈ

**λ¬Έμ : ONNX λ¨λΈμ„ λ΅λ“ν•  μ μ—†μ**

```
Error loading model: Failed to fetch
```

**ν•΄κ²° λ°©λ²•:**
- `decoder.onnx` νμΌμ΄ κ°™μ€ λ””λ ‰ν† λ¦¬μ— μλ”μ§€ ν™•μΈ
- HTTP μ„λ²„κ°€ μ •μ  νμΌμ„ μ λ€λ΅ μ„λΉ™ν•λ”μ§€ ν™•μΈ
- CORS μ„¤μ • ν™•μΈ

**λ¬Έμ : WebGL/WebNNμ„ μ‚¬μ©ν•  μ μ—†μ**

λΈλΌμ°μ €κ°€ GPU κ°€μ†μ„ μ§€μ›ν•μ§€ μ•λ” κ²½μ° CPUλ΅ ν΄λ°±λ©λ‹λ‹¤. μ„±λ¥μ΄ μ €ν•λ  μ μμµλ‹λ‹¤.

**ν•΄κ²° λ°©λ²•:**
- μµμ‹  λΈλΌμ°μ € μ‚¬μ©
- GPU λ“λΌμ΄λ²„ μ—…λ°μ΄νΈ
- λΈλΌμ°μ € ν•λ“μ›¨μ–΄ κ°€μ† μ„¤μ • ν™•μΈ

**λ¬Έμ : λ©”λ¨λ¦¬ λ¶€μ΅±**

λ€μ©λ‰ ν™”λ©΄ ν•΄μƒλ„μ—μ„ λ©”λ¨λ¦¬ λ¶€μ΅±μ΄ λ°μƒν•  μ μμµλ‹λ‹¤.

**ν•΄κ²° λ°©λ²•:**
- ν•΄μƒλ„ λ‚®μ¶”κΈ° (μ„λ²„ μ„¤μ •)
- λΈλΌμ°μ € λ©”λ¨λ¦¬ μ ν• ν™•μΈ
- λ‹¤λ¥Έ νƒ­/μ• ν”λ¦¬μΌ€μ΄μ… μΆ…λ£

## π“ μ„±λ¥ μ§€ν‘

μΌλ°μ μΈ μ„±λ¥ μ§€ν‘:

- **λ””μ½”λ”© μ‹κ°„**: 5-20ms (GPU μ‚¬μ© μ‹)
- **FPS**: 30-60 FPS (λ„¤νΈμ›ν¬ λ° GPU μ„±λ¥μ— λ”°λΌ λ‹¤λ¦„)
- **μ§€μ—°μ‹κ°„**: 50-200ms (λ„¤νΈμ›ν¬ μ§€μ—° ν¬ν•¨)

## π“ μ°Έκ³ μ‚¬ν•­

- μ„λ²„μ™€ ν΄λΌμ΄μ–ΈνΈμ λ¨λΈ κµ¬μ΅°κ°€ μΌμΉν•΄μ•Ό ν•©λ‹λ‹¤
- μ–‘μν™” μ¤μΌ€μΌ(`scale`)μ€ μ„λ²„μ—μ„ κ³„μ‚°λμ–΄ ν—¤λ”μ— ν¬ν•¨λ©λ‹λ‹¤
- νƒ€μ„μ¤νƒ¬ν”„λ” μ„λ²„ μ‹κ°„ κΈ°μ¤€μ΄λ―€λ΅, ν΄λΌμ΄μ–ΈνΈμ™€ μ„λ²„μ μ‹κ³„ λ™κΈ°ν™”κ°€ ν•„μ”ν•©λ‹λ‹¤
- `test_client.py`λ” ν™”λ©΄ ν‘μ‹ μ—†μ΄ μ„±λ¥ ν†µκ³„λ§ μ¶λ ¥ν•©λ‹λ‹¤ (ν™”λ©΄ ν‘μ‹κ°€ ν•„μ”ν• κ²½μ° μ›Ή ν΄λΌμ΄μ–ΈνΈ μ‚¬μ©)
- μ›Ή ν΄λΌμ΄μ–ΈνΈλ” λ³΄μ•μƒμ μ΄μ λ΅ λ΅μ»¬ νμΌ μ‹μ¤ν…μ—μ„ μ§μ ‘ μ—΄ μ μ—†μµλ‹λ‹¤ (HTTP μ„λ²„ ν•„μ”)
- μ„λ²„μ™€ ν΄λΌμ΄μ–ΈνΈλ” Docker μ»¨ν…μ΄λ„λ΅ μ‹¤ν–‰λ©λ‹λ‹¤
- μ„λ²„ μ»¨ν…μ΄λ„λ” ν¬νΈ 8765λ¥Ό νΈμ¤νΈμ— λ…Έμ¶ν•©λ‹λ‹¤
- ν΄λΌμ΄μ–ΈνΈ μ»¨ν…μ΄λ„λ” `--network host` λ¨λ“λ΅ μ‹¤ν–‰λμ–΄ μ„λ²„μ `localhost:8765`μ— μ—°κ²°ν•©λ‹λ‹¤
- μ›Ή ν΄λΌμ΄μ–ΈνΈλ„ μ„λ²„κ°€ Dockerλ΅ μ‹¤ν–‰ μ¤‘μ΄λ©΄ `ws://localhost:8765`λ΅ μ—°κ²°ν•  μ μμµλ‹λ‹¤
- NVIDIA Container Toolkitμ΄ μ„¤μΉλμ–΄ μμ–΄μ•Ό GPUλ¥Ό μ‚¬μ©ν•  μ μμµλ‹λ‹¤

## π”— κ΄€λ ¨ νμΌ

- `server_encode.py`: μ„λ²„ μΈ΅ μΈμ½”λ”© μ½”λ“
- `decoder_model.py`: λ””μ½”λ” λ¨λΈ μ •μ
- `encoder_model.py`: μΈμ½”λ” λ¨λΈ μ •μ (μ„λ²„ μΈ΅)

## π“„ λΌμ΄μ„ μ¤

μ΄ ν”„λ΅μ νΈμ λΌμ΄μ„ μ¤ μ •λ³΄λ¥Ό μ—¬κΈ°μ— μ¶”κ°€ν•μ„Έμ”.

